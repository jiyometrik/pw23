{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data processing\n",
    "import string\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# natural language processing\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from funcsigs import signature\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import (auc, average_precision_score,\n",
    "                             precision_recall_curve, roc_curve)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.data.path.append(\"/usr/share/nltk_data/\")\n",
    "\n",
    "# matplotlib things\n",
    "plt.style.use(\"seaborn-v0_8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "df = pd.read_csv(\"./data/combined_sentiments.csv\",\n",
    "                 header=0,\n",
    "                 sep=\",\",\n",
    "                 on_bad_lines=\"skip\")\n",
    "\n",
    "# lemmatise\n",
    "\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    \"\"\"identify each word by its part of speech\n",
    "    and return that part of speech, for lemmatisation.\"\"\"\n",
    "    if tag.startswith(\"J\"):\n",
    "        return wordnet.ADJ\n",
    "    if tag.startswith(\"V\"):\n",
    "        return wordnet.VERB\n",
    "    if tag.startswith(\"N\"):\n",
    "        return wordnet.NOUN\n",
    "    if tag.startswith(\"R\"):\n",
    "        return wordnet.ADV\n",
    "    return wordnet.NOUN\n",
    "\n",
    "\n",
    "# check whether there is a digit or not\n",
    "\n",
    "\n",
    "def check_digits(text):\n",
    "    \"\"\"check whether a piece of text\n",
    "    contains numerical digits.\"\"\"\n",
    "    return any(i.isdigit() for i in text)\n",
    "\n",
    "\n",
    "# tokenise\n",
    "\n",
    "\n",
    "def clean_review(review):\n",
    "    \"\"\"removes stop words from each review,\n",
    "    then tokensises them.\"\"\"\n",
    "    review = str(review)\n",
    "    review = review.lower() # turn into lowercase\n",
    "    review = [word.strip(string.punctuation)\n",
    "              for word in review.split(\" \")] # remove punctuation\n",
    "    # remove digits\n",
    "    review = [word for word in review if not check_digits(word)]\n",
    "\n",
    "    # remove stop words\n",
    "    stop = stopwords.words(\"english\")\n",
    "    review = [token for token in review if token not in stop]\n",
    "    # remove empty tokens\n",
    "    review = [token for token in review if len(token) > 0]\n",
    "\n",
    "    # tag each token with its part of speech (pos)\n",
    "    pos_tags = pos_tag(review)\n",
    "    review = [\n",
    "        WordNetLemmatizer().lemmatize(tag[0], get_wordnet_pos(tag[1]))\n",
    "        for tag in pos_tags\n",
    "    ]\n",
    "\n",
    "    # remove words with only one letter\n",
    "    review = [token for token in review if len(token) > 1]\n",
    "    review = \" \".join(review)\n",
    "    return review\n",
    "# print(type(clean_review(\"Housekeeper kept our rooms clean. Skyline studios very spacious & modern. Lovely big bathroom with well stocked amenities. Poolside seating & Olympic-sized pool was enjoyable.\")))\n",
    "# print(clean_review(\"Housekeeper kept our rooms clean. Skyline studios very spacious & modern. Lovely big bathroom with well stocked amenities. Poolside seating & Olympic-sized pool was enjoyable.\"))\n",
    "\n",
    "# generate a cleaned, tokenised and lemmatised version of the reviews\n",
    "df[\"reviews.clean\"] = df[\"reviews.text\"].apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a frequency dictionary\n",
    "def build_freqs():\n",
    "\t'''\n",
    "\ttakes reviews and their polarities as input,\n",
    "\tgo through every tweet, preprocess them, count\n",
    "\tthe occurrence of every word in the data set and\n",
    "\tcreate a frequency dictionary.\n",
    "\t'''\n",
    "\treviews = df['reviews.clean'].tolist()\n",
    "\tpolarities = df['sent.net'].tolist()\n",
    "\t# print(reviews[:7], polarities[:7])\n",
    "\tfreqs = {}\n",
    "\tfor review, polarity in zip(reviews, polarities):\n",
    "\t\tfor word in review.split():\n",
    "\t\t\tpair = (word, polarity)\n",
    "\t\t\tfreqs[pair] = freqs.get(pair, 0) + 1\n",
    "\treturn freqs\n",
    "\n",
    "# print(build_freqs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "\t'''\n",
    "\tcalculate the sigmoid of z.\n",
    "\t'''\n",
    "\th = 1 / (1 + np.exp(-z))\n",
    "\treturn h\n",
    "\n",
    "def gradient_descent(x, y, theta, alpha, iters):\n",
    "\t'''\n",
    "\tinput:\n",
    "\t\tx: matrix of features, dimensions m by n + 1\n",
    "\t\ty: corresponding labels of the input matrix x\n",
    "\t\ttheta: weight vector of dimensions n + 1 by 1\n",
    "\t\talpha: learning rate\n",
    "\t\titers: number of training iterations on the model\n",
    "\toutput:\n",
    "\t\tj: final cost\t\n",
    "\t\ttheta: final weight vector\n",
    "\t'''\n",
    "\tm = len(x)\n",
    "\tfor _ in range(0, iters):\n",
    "\t\tz = np.dot(x, theta)\n",
    "\t\th = sigmoid(z)\n",
    "\t\tj = (-1 / m) * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))\n",
    "\t\ttheta = theta - (alpha / m) * np.dot(x.T, h - y)\n",
    "\t\tprint(j)\n",
    "\tj = float(j)\n",
    "\treturn j, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(review, freqs):\n",
    "\tx = np.zeros((1, 3))\n",
    "\t# set bias value to 1\n",
    "\tx[0, 0] = 1\n",
    "\tfor word in review.split():\n",
    "\t\t# increment the word count for the positive label 1\n",
    "\t\tx[0, 1] += freqs.get((word, 1), 0)\n",
    "\t\t# increment the word count for the negative label 0\n",
    "\t\tx[0, 2] += freqs.get((word, 0), 0)\n",
    "\tassert(x.shape == (1,3))\n",
    "\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a 70-30 train-test split\n",
    "train_pos = df[df['sent.net']==1]['reviews.clean'].tolist()[:7001]\n",
    "# print((test_pos))\n",
    "test_pos = df[df['sent.net']==1]['reviews.clean'].tolist()[7001:]\n",
    "train_neg = df[df['sent.net']==-1]['reviews.clean'].tolist()[7001:]\n",
    "test_neg = df[df['sent.net']==-1]['reviews.clean'].tolist()[:7001]\n",
    "train_x = train_pos + train_neg\n",
    "test_x = test_pos + test_neg\n",
    "# combine positive and negative labels\n",
    "train_y = np.append(np.ones((len(train_pos), 1)), np.zeros((len(train_neg), 1)), axis=0)\n",
    "test_y = np.append(np.ones((len(test_pos), 1)), np.zeros((len(test_neg), 1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69314718]]\n",
      "[[0.66369683]]\n",
      "[[0.63677128]]\n",
      "[[0.61212213]]\n",
      "[[0.5895107]]\n",
      "[[0.56871654]]\n",
      "[[0.5495413]]\n",
      "[[0.53180937]]\n",
      "[[0.51536663]]\n",
      "[[0.50007841]]\n",
      "[[0.4858271]]\n",
      "[[0.47250993]]\n",
      "[[0.4600369]]\n",
      "[[0.448329]]\n",
      "[[0.43731666]]\n",
      "[[0.42693842]]\n",
      "[[0.41713984]]\n",
      "[[0.40787251]]\n",
      "[[0.39909328]]\n",
      "[[0.39076354]]\n",
      "[[0.38284869]]\n",
      "[[0.37531759]]\n",
      "[[0.36814216]]\n",
      "[[0.36129702]]\n",
      "[[0.35475917]]\n",
      "[[0.3485077]]\n",
      "[[0.34252357]]\n",
      "[[0.33678944]]\n",
      "[[0.33128941]]\n",
      "[[0.32600893]]\n",
      "[[0.32093466]]\n",
      "[[0.3160543]]\n",
      "[[0.31135655]]\n",
      "[[0.30683096]]\n",
      "[[0.30246788]]\n",
      "[[0.29825838]]\n",
      "[[0.29419418]]\n",
      "[[0.29026758]]\n",
      "[[0.28647143]]\n",
      "[[0.28279909]]\n",
      "[[0.27924433]]\n",
      "[[0.27580138]]\n",
      "[[0.27246481]]\n",
      "[[0.26922957]]\n",
      "[[0.26609091]]\n",
      "[[0.26304438]]\n",
      "[[0.26008582]]\n",
      "[[0.25721129]]\n",
      "[[0.25441711]]\n",
      "[[0.25169981]]\n",
      "[[0.24905612]]\n",
      "[[0.24648294]]\n",
      "[[0.24397736]]\n",
      "[[0.24153664]]\n",
      "[[0.23915817]]\n",
      "[[0.23683948]]\n",
      "[[0.23457824]]\n",
      "[[0.23237225]]\n",
      "[[0.2302194]]\n",
      "[[0.22811771]]\n",
      "[[0.22606528]]\n",
      "[[0.22406031]]\n",
      "[[0.22210111]]\n",
      "[[0.22018604]]\n",
      "[[0.21831355]]\n",
      "[[0.21648217]]\n",
      "[[0.21469049]]\n",
      "[[0.21293717]]\n",
      "[[0.21122092]]\n",
      "[[0.20954052]]\n",
      "[[0.2078948]]\n",
      "[[0.20628265]]\n",
      "[[0.20470299]]\n",
      "[[0.2031548]]\n",
      "[[0.2016371]]\n",
      "[[0.20014894]]\n",
      "[[0.19868944]]\n",
      "[[0.19725772]]\n",
      "[[0.19585295]]\n",
      "[[0.19447434]]\n",
      "[[0.19312113]]\n",
      "[[0.19179259]]\n",
      "[[0.190488]]\n",
      "[[0.18920669]]\n",
      "[[0.18794801]]\n",
      "[[0.18671132]]\n",
      "[[0.18549604]]\n",
      "[[0.18430157]]\n",
      "[[0.18312735]]\n",
      "[[0.18197285]]\n",
      "[[0.18083754]]\n",
      "[[0.17972092]]\n",
      "[[0.17862252]]\n",
      "[[0.17754185]]\n",
      "[[0.17647847]]\n",
      "[[0.17543194]]\n",
      "[[0.17440185]]\n",
      "[[0.17338778]]\n",
      "[[0.17238935]]\n",
      "[[0.17140617]]\n",
      "[[0.17043788]]\n",
      "[[0.16948412]]\n",
      "[[0.16854454]]\n",
      "[[0.16761882]]\n",
      "[[0.16670663]]\n",
      "[[0.16580766]]\n",
      "[[0.1649216]]\n",
      "[[0.16404817]]\n",
      "[[0.16318708]]\n",
      "[[0.16233805]]\n",
      "[[0.16150082]]\n",
      "[[0.16067513]]\n",
      "[[0.15986072]]\n",
      "[[0.15905735]]\n",
      "[[0.15826479]]\n",
      "[[0.15748281]]\n",
      "[[0.15671117]]\n",
      "[[0.15594967]]\n",
      "[[0.1551981]]\n",
      "[[0.15445625]]\n",
      "[[0.15372391]]\n",
      "[[0.15300091]]\n",
      "[[0.15228704]]\n",
      "[[0.15158213]]\n",
      "[[0.15088599]]\n",
      "[[0.15019846]]\n",
      "[[0.14951937]]\n",
      "[[0.14884855]]\n",
      "[[0.14818584]]\n",
      "[[0.14753108]]\n",
      "[[0.14688413]]\n",
      "[[0.14624484]]\n",
      "[[0.14561306]]\n",
      "[[0.14498865]]\n",
      "[[0.14437148]]\n",
      "[[0.14376142]]\n",
      "[[0.14315832]]\n",
      "[[0.14256207]]\n",
      "[[0.14197255]]\n",
      "[[0.14138963]]\n",
      "[[0.14081319]]\n",
      "[[0.14024312]]\n",
      "[[0.13967932]]\n",
      "[[0.13912166]]\n",
      "[[0.13857004]]\n",
      "[[0.13802436]]\n",
      "[[0.13748452]]\n",
      "[[0.13695042]]\n",
      "[[0.13642196]]\n",
      "[[0.13589904]]\n",
      "[[0.13538157]]\n",
      "[[0.13486947]]\n",
      "[[0.13436264]]\n",
      "[[0.133861]]\n",
      "[[0.13336446]]\n",
      "[[0.13287295]]\n",
      "[[0.13238637]]\n",
      "[[0.13190465]]\n",
      "[[0.13142771]]\n",
      "[[0.13095548]]\n",
      "[[0.13048789]]\n",
      "[[0.13002485]]\n",
      "[[0.12956631]]\n",
      "[[0.12911218]]\n",
      "[[0.12866241]]\n",
      "[[0.12821692]]\n",
      "[[0.12777566]]\n",
      "[[0.12733855]]\n",
      "[[0.12690553]]\n",
      "[[0.12647655]]\n",
      "[[0.12605154]]\n",
      "[[0.12563044]]\n",
      "[[0.12521321]]\n",
      "[[0.12479977]]\n",
      "[[0.12439008]]\n",
      "[[0.12398407]]\n",
      "[[0.12358171]]\n",
      "[[0.12318293]]\n",
      "[[0.12278769]]\n",
      "[[0.12239593]]\n",
      "[[0.12200761]]\n",
      "[[0.12162267]]\n",
      "[[0.12124108]]\n",
      "[[0.12086278]]\n",
      "[[0.12048773]]\n",
      "[[0.12011588]]\n",
      "[[0.11974719]]\n",
      "[[0.11938162]]\n",
      "[[0.11901912]]\n",
      "[[0.11865966]]\n",
      "[[0.11830319]]\n",
      "[[0.11794967]]\n",
      "[[0.11759907]]\n",
      "[[0.11725134]]\n",
      "[[0.11690645]]\n",
      "[[0.11656436]]\n",
      "[[0.11622503]]\n",
      "[[0.11588844]]\n",
      "[[0.11555453]]\n",
      "[[0.11522329]]\n",
      "[[0.11489467]]\n",
      "[[0.11456864]]\n",
      "[[0.11424518]]\n",
      "[[0.11392423]]\n",
      "[[0.11360579]]\n",
      "[[0.11328981]]\n",
      "[[0.11297626]]\n",
      "[[0.11266511]]\n",
      "[[0.11235634]]\n",
      "[[0.11204991]]\n",
      "[[0.1117458]]\n",
      "[[0.11144398]]\n",
      "[[0.11114442]]\n",
      "[[0.11084709]]\n",
      "[[0.11055197]]\n",
      "[[0.11025903]]\n",
      "[[0.10996825]]\n",
      "[[0.10967959]]\n",
      "[[0.10939304]]\n",
      "[[0.10910857]]\n",
      "[[0.10882615]]\n",
      "[[0.10854576]]\n",
      "[[0.10826739]]\n",
      "[[0.107991]]\n",
      "[[0.10771657]]\n",
      "[[0.10744408]]\n",
      "[[0.10717351]]\n",
      "[[0.10690483]]\n",
      "[[0.10663803]]\n",
      "[[0.10637309]]\n",
      "[[0.10610997]]\n",
      "[[0.10584868]]\n",
      "[[0.10558917]]\n",
      "[[0.10533144]]\n",
      "[[0.10507546]]\n",
      "[[0.10482121]]\n",
      "[[0.10456868]]\n",
      "[[0.10431785]]\n",
      "[[0.10406869]]\n",
      "[[0.1038212]]\n",
      "[[0.10357535]]\n",
      "[[0.10333113]]\n",
      "[[0.10308851]]\n",
      "[[0.10284748]]\n",
      "[[0.10260803]]\n",
      "[[0.10237014]]\n",
      "[[0.10213379]]\n",
      "[[0.10189896]]\n",
      "[[0.10166564]]\n",
      "[[0.10143382]]\n",
      "[[0.10120347]]\n",
      "[[0.10097459]]\n",
      "[[0.10074716]]\n",
      "[[0.10052116]]\n",
      "[[0.10029658]]\n",
      "[[0.10007341]]\n",
      "[[0.09985162]]\n",
      "[[0.09963121]]\n",
      "[[0.09941217]]\n",
      "[[0.09919447]]\n",
      "[[0.09897811]]\n",
      "[[0.09876308]]\n",
      "[[0.09854935]]\n",
      "[[0.09833692]]\n",
      "[[0.09812578]]\n",
      "[[0.09791591]]\n",
      "[[0.09770729]]\n",
      "[[0.09749993]]\n",
      "[[0.09729379]]\n",
      "[[0.09708889]]\n",
      "[[0.09688519]]\n",
      "[[0.0966827]]\n",
      "[[0.09648139]]\n",
      "[[0.09628126]]\n",
      "[[0.0960823]]\n",
      "[[0.09588449]]\n",
      "[[0.09568783]]\n",
      "[[0.0954923]]\n",
      "[[0.0952979]]\n",
      "[[0.09510461]]\n",
      "[[0.09491242]]\n",
      "[[0.09472132]]\n",
      "[[0.09453131]]\n",
      "[[0.09434237]]\n",
      "[[0.09415449]]\n",
      "[[0.09396767]]\n",
      "[[0.09378189]]\n",
      "[[0.09359714]]\n",
      "[[0.09341342]]\n",
      "[[0.09323072]]\n",
      "[[0.09304902]]\n",
      "[[0.09286832]]\n",
      "[[0.09268862]]\n",
      "[[0.09250989]]\n",
      "[[0.09233213]]\n",
      "[[0.09215533]]\n",
      "[[0.0919795]]\n",
      "[[0.0918046]]\n",
      "[[0.09163065]]\n",
      "[[0.09145763]]\n",
      "[[0.09128552]]\n",
      "[[0.09111434]]\n",
      "[[0.09094406]]\n",
      "[[0.09077467]]\n",
      "[[0.09060618]]\n",
      "[[0.09043858]]\n",
      "[[0.09027184]]\n",
      "[[0.09010598]]\n",
      "[[0.08994098]]\n",
      "[[0.08977683]]\n",
      "[[0.08961353]]\n",
      "[[0.08945107]]\n",
      "[[0.08928944]]\n",
      "[[0.08912864]]\n",
      "[[0.08896866]]\n",
      "[[0.08880949]]\n",
      "[[0.08865112]]\n",
      "[[0.08849356]]\n",
      "[[0.08833679]]\n",
      "[[0.0881808]]\n",
      "[[0.0880256]]\n",
      "[[0.08787116]]\n",
      "[[0.0877175]]\n",
      "[[0.0875646]]\n",
      "[[0.08741245]]\n",
      "[[0.08726105]]\n",
      "[[0.08711039]]\n",
      "[[0.08696047]]\n",
      "[[0.08681129]]\n",
      "[[0.08666282]]\n",
      "[[0.08651508]]\n",
      "[[0.08636805]]\n",
      "[[0.08622174]]\n",
      "[[0.08607612]]\n",
      "[[0.0859312]]\n",
      "[[0.08578698]]\n",
      "[[0.08564344]]\n",
      "[[0.08550058]]\n",
      "[[0.0853584]]\n",
      "[[0.08521689]]\n",
      "[[0.08507605]]\n",
      "[[0.08493587]]\n",
      "[[0.08479634]]\n",
      "[[0.08465747]]\n",
      "[[0.08451924]]\n",
      "[[0.08438166]]\n",
      "[[0.08424471]]\n",
      "[[0.08410839]]\n",
      "[[0.0839727]]\n",
      "[[0.08383763]]\n",
      "[[0.08370318]]\n",
      "[[0.08356934]]\n",
      "[[0.08343611]]\n",
      "[[0.08330348]]\n",
      "[[0.08317146]]\n",
      "[[0.08304003]]\n",
      "[[0.08290919]]\n",
      "[[0.08277894]]\n",
      "[[0.08264927]]\n",
      "[[0.08252018]]\n",
      "[[0.08239166]]\n",
      "[[0.08226372]]\n",
      "[[0.08213634]]\n",
      "[[0.08200952]]\n",
      "[[0.08188326]]\n",
      "[[0.08175755]]\n",
      "[[0.08163239]]\n",
      "[[0.08150778]]\n",
      "[[0.08138371]]\n",
      "[[0.08126018]]\n",
      "[[0.08113718]]\n",
      "[[0.08101472]]\n",
      "[[0.08089278]]\n",
      "[[0.08077136]]\n",
      "[[0.08065047]]\n",
      "[[0.08053009]]\n",
      "[[0.08041022]]\n",
      "[[0.08029087]]\n",
      "[[0.08017202]]\n",
      "[[0.08005367]]\n",
      "[[0.07993582]]\n",
      "[[0.07981846]]\n",
      "[[0.0797016]]\n",
      "[[0.07958522]]\n",
      "[[0.07946933]]\n",
      "[[0.07935393]]\n",
      "[[0.079239]]\n",
      "[[0.07912455]]\n",
      "[[0.07901056]]\n",
      "[[0.07889705]]\n",
      "[[0.07878401]]\n",
      "[[0.07867143]]\n",
      "[[0.0785593]]\n",
      "[[0.07844764]]\n",
      "[[0.07833643]]\n",
      "[[0.07822566]]\n",
      "[[0.07811535]]\n",
      "[[0.07800548]]\n",
      "[[0.07789606]]\n",
      "[[0.07778707]]\n",
      "[[0.07767852]]\n",
      "[[0.0775704]]\n",
      "[[0.07746272]]\n",
      "[[0.07735546]]\n",
      "[[0.07724863]]\n",
      "[[0.07714221]]\n",
      "[[0.07703622]]\n",
      "[[0.07693065]]\n",
      "[[0.07682549]]\n",
      "[[0.07672074]]\n",
      "[[0.0766164]]\n",
      "[[0.07651247]]\n",
      "[[0.07640894]]\n",
      "[[0.07630581]]\n",
      "[[0.07620309]]\n",
      "[[0.07610075]]\n",
      "[[0.07599882]]\n",
      "[[0.07589727]]\n",
      "[[0.07579611]]\n",
      "[[0.07569534]]\n",
      "[[0.07559496]]\n",
      "[[0.07549495]]\n",
      "[[0.07539533]]\n",
      "[[0.07529608]]\n",
      "[[0.0751972]]\n",
      "[[0.0750987]]\n",
      "[[0.07500057]]\n",
      "[[0.07490281]]\n",
      "[[0.07480541]]\n",
      "[[0.07470838]]\n",
      "[[0.07461171]]\n",
      "[[0.07451539]]\n",
      "[[0.07441944]]\n",
      "[[0.07432384]]\n",
      "[[0.07422859]]\n",
      "[[0.07413369]]\n",
      "[[0.07403914]]\n",
      "[[0.07394494]]\n",
      "[[0.07385108]]\n",
      "[[0.07375756]]\n",
      "[[0.07366439]]\n",
      "[[0.07357155]]\n",
      "[[0.07347905]]\n",
      "[[0.07338688]]\n",
      "[[0.07329505]]\n",
      "[[0.07320354]]\n",
      "[[0.07311237]]\n",
      "[[0.07302152]]\n",
      "[[0.07293099]]\n",
      "[[0.07284079]]\n",
      "[[0.07275091]]\n",
      "[[0.07266135]]\n",
      "[[0.07257211]]\n",
      "[[0.07248318]]\n",
      "[[0.07239456]]\n",
      "[[0.07230626]]\n",
      "[[0.07221826]]\n",
      "[[0.07213058]]\n",
      "[[0.0720432]]\n",
      "[[0.07195613]]\n",
      "[[0.07186935]]\n",
      "[[0.07178288]]\n",
      "[[0.07169671]]\n",
      "[[0.07161084]]\n",
      "[[0.07152527]]\n",
      "[[0.07143998]]\n",
      "[[0.071355]]\n",
      "[[0.0712703]]\n",
      "[[0.07118589]]\n",
      "[[0.07110177]]\n",
      "[[0.07101794]]\n",
      "[[0.07093439]]\n",
      "[[0.07085113]]\n",
      "[[0.07076814]]\n",
      "[[0.07068544]]\n",
      "[[0.07060302]]\n",
      "[[0.07052087]]\n",
      "[[0.070439]]\n",
      "[[0.0703574]]\n",
      "[[0.07027608]]\n",
      "[[0.07019502]]\n",
      "[[0.07011424]]\n",
      "[[0.07003373]]\n",
      "[[0.06995348]]\n",
      "[[0.06987349]]\n",
      "[[0.06979377]]\n",
      "[[0.06971432]]\n",
      "[[0.06963512]]\n",
      "[[0.06955619]]\n",
      "[[0.06947751]]\n",
      "[[0.06939909]]\n",
      "[[0.06932092]]\n",
      "[[0.06924301]]\n",
      "[[0.06916536]]\n",
      "[[0.06908795]]\n",
      "[[0.06901079]]\n",
      "[[0.06893389]]\n",
      "[[0.06885723]]\n",
      "[[0.06878081]]\n",
      "[[0.06870465]]\n",
      "[[0.06862872]]\n",
      "[[0.06855304]]\n",
      "[[0.0684776]]\n",
      "[[0.0684024]]\n",
      "[[0.06832744]]\n",
      "[[0.06825271]]\n",
      "[[0.06817823]]\n",
      "[[0.06810397]]\n",
      "[[0.06802995]]\n",
      "[[0.06795617]]\n",
      "[[0.06788261]]\n",
      "[[0.06780929]]\n",
      "[[0.06773619]]\n",
      "[[0.06766333]]\n",
      "[[0.06759068]]\n",
      "[[0.06751827]]\n",
      "[[0.06744608]]\n",
      "[[0.06737411]]\n",
      "[[0.06730237]]\n",
      "[[0.06723084]]\n",
      "[[0.06715954]]\n",
      "[[0.06708846]]\n",
      "[[0.06701759]]\n",
      "[[0.06694694]]\n",
      "[[0.0668765]]\n",
      "[[0.06680628]]\n",
      "[[0.06673628]]\n",
      "[[0.06666648]]\n",
      "[[0.0665969]]\n",
      "[[0.06652753]]\n",
      "[[0.06645837]]\n",
      "[[0.06638941]]\n",
      "[[0.06632067]]\n",
      "[[0.06625213]]\n",
      "[[0.06618379]]\n",
      "[[0.06611566]]\n",
      "[[0.06604773]]\n",
      "[[0.06598001]]\n",
      "[[0.06591248]]\n",
      "[[0.06584516]]\n",
      "[[0.06577803]]\n",
      "[[0.06571111]]\n",
      "[[0.06564438]]\n",
      "[[0.06557785]]\n",
      "[[0.06551151]]\n",
      "[[0.06544537]]\n",
      "[[0.06537942]]\n",
      "[[0.06531367]]\n",
      "[[0.0652481]]\n",
      "[[0.06518273]]\n",
      "[[0.06511755]]\n",
      "[[0.06505256]]\n",
      "[[0.06498775]]\n",
      "[[0.06492313]]\n",
      "[[0.0648587]]\n",
      "[[0.06479446]]\n",
      "[[0.0647304]]\n",
      "[[0.06466652]]\n",
      "[[0.06460283]]\n",
      "[[0.06453932]]\n",
      "[[0.06447599]]\n",
      "[[0.06441284]]\n",
      "[[0.06434987]]\n",
      "[[0.06428708]]\n",
      "[[0.06422446]]\n",
      "[[0.06416203]]\n",
      "[[0.06409977]]\n",
      "[[0.06403768]]\n",
      "[[0.06397577]]\n",
      "[[0.06391404]]\n",
      "[[0.06385248]]\n",
      "[[0.06379109]]\n",
      "[[0.06372987]]\n",
      "[[0.06366882]]\n",
      "[[0.06360794]]\n",
      "[[0.06354723]]\n",
      "[[0.06348669]]\n",
      "[[0.06342632]]\n",
      "[[0.06336612]]\n",
      "[[0.06330608]]\n",
      "[[0.0632462]]\n",
      "[[0.06318649]]\n",
      "[[0.06312695]]\n",
      "[[0.06306757]]\n",
      "[[0.06300835]]\n",
      "[[0.06294929]]\n",
      "[[0.0628904]]\n",
      "[[0.06283166]]\n",
      "[[0.06277308]]\n",
      "[[0.06271467]]\n",
      "[[0.06265641]]\n",
      "[[0.0625983]]\n",
      "[[0.06254036]]\n",
      "[[0.06248257]]\n",
      "[[0.06242494]]\n",
      "[[0.06236746]]\n",
      "[[0.06231014]]\n",
      "[[0.06225296]]\n",
      "[[0.06219595]]\n",
      "[[0.06213908]]\n",
      "[[0.06208237]]\n",
      "[[0.0620258]]\n",
      "[[0.06196939]]\n",
      "[[0.06191312]]\n",
      "[[0.06185701]]\n",
      "[[0.06180104]]\n",
      "[[0.06174522]]\n",
      "[[0.06168955]]\n",
      "[[0.06163402]]\n",
      "[[0.06157864]]\n",
      "[[0.06152341]]\n",
      "[[0.06146832]]\n",
      "[[0.06141337]]\n",
      "[[0.06135856]]\n",
      "[[0.0613039]]\n",
      "[[0.06124938]]\n",
      "[[0.061195]]\n",
      "[[0.06114077]]\n",
      "[[0.06108667]]\n",
      "[[0.06103271]]\n",
      "[[0.06097889]]\n",
      "[[0.06092521]]\n",
      "[[0.06087167]]\n",
      "[[0.06081826]]\n",
      "[[0.060765]]\n",
      "[[0.06071186]]\n",
      "[[0.06065887]]\n",
      "[[0.060606]]\n",
      "[[0.06055328]]\n",
      "[[0.06050068]]\n",
      "[[0.06044822]]\n",
      "[[0.0603959]]\n",
      "[[0.0603437]]\n",
      "[[0.06029164]]\n",
      "[[0.0602397]]\n",
      "[[0.0601879]]\n",
      "[[0.06013623]]\n",
      "[[0.06008469]]\n",
      "[[0.06003327]]\n",
      "[[0.05998199]]\n",
      "[[0.05993083]]\n",
      "[[0.0598798]]\n",
      "[[0.0598289]]\n",
      "[[0.05977813]]\n",
      "[[0.05972747]]\n",
      "[[0.05967695]]\n",
      "[[0.05962655]]\n",
      "[[0.05957627]]\n",
      "[[0.05952612]]\n",
      "[[0.05947609]]\n",
      "[[0.05942619]]\n",
      "[[0.05937641]]\n",
      "[[0.05932674]]\n",
      "[[0.0592772]]\n",
      "[[0.05922779]]\n",
      "[[0.05917849]]\n",
      "[[0.05912931]]\n",
      "[[0.05908025]]\n",
      "[[0.05903131]]\n",
      "[[0.05898249]]\n",
      "[[0.05893379]]\n",
      "[[0.0588852]]\n",
      "[[0.05883673]]\n",
      "[[0.05878838]]\n",
      "[[0.05874014]]\n",
      "[[0.05869202]]\n",
      "[[0.05864402]]\n",
      "[[0.05859613]]\n",
      "[[0.05854835]]\n",
      "[[0.05850069]]\n",
      "[[0.05845314]]\n",
      "[[0.05840571]]\n",
      "[[0.05835839]]\n",
      "[[0.05831118]]\n",
      "[[0.05826408]]\n",
      "[[0.05821709]]\n",
      "[[0.05817022]]\n",
      "[[0.05812345]]\n",
      "[[0.0580768]]\n",
      "[[0.05803025]]\n",
      "[[0.05798381]]\n",
      "[[0.05793749]]\n",
      "[[0.05789127]]\n",
      "[[0.05784516]]\n",
      "[[0.05779915]]\n",
      "[[0.05775326]]\n",
      "[[0.05770747]]\n",
      "[[0.05766178]]\n",
      "[[0.0576162]]\n",
      "[[0.05757073]]\n",
      "[[0.05752537]]\n",
      "[[0.0574801]]\n",
      "[[0.05743495]]\n",
      "[[0.05738989]]\n",
      "[[0.05734494]]\n",
      "[[0.05730009]]\n",
      "[[0.05725535]]\n",
      "[[0.05721071]]\n",
      "[[0.05716617]]\n",
      "[[0.05712173]]\n",
      "[[0.05707739]]\n",
      "[[0.05703316]]\n",
      "[[0.05698902]]\n",
      "[[0.05694499]]\n",
      "[[0.05690105]]\n",
      "[[0.05685721]]\n",
      "[[0.05681348]]\n",
      "[[0.05676984]]\n",
      "[[0.0567263]]\n",
      "[[0.05668285]]\n",
      "[[0.05663951]]\n",
      "[[0.05659626]]\n",
      "[[0.05655311]]\n",
      "[[0.05651006]]\n",
      "[[0.0564671]]\n",
      "[[0.05642424]]\n",
      "[[0.05638147]]\n",
      "[[0.0563388]]\n",
      "[[0.05629622]]\n",
      "[[0.05625374]]\n",
      "[[0.05621135]]\n",
      "[[0.05616906]]\n",
      "[[0.05612686]]\n",
      "[[0.05608475]]\n",
      "[[0.05604273]]\n",
      "[[0.05600081]]\n",
      "[[0.05595898]]\n",
      "[[0.05591724]]\n",
      "[[0.05587559]]\n",
      "[[0.05583403]]\n",
      "[[0.05579257]]\n",
      "[[0.05575119]]\n",
      "[[0.05570991]]\n",
      "[[0.05566871]]\n",
      "[[0.0556276]]\n",
      "[[0.05558659]]\n",
      "[[0.05554566]]\n",
      "[[0.05550482]]\n",
      "[[0.05546407]]\n",
      "[[0.0554234]]\n",
      "[[0.05538283]]\n",
      "[[0.05534234]]\n",
      "[[0.05530194]]\n",
      "[[0.05526162]]\n",
      "[[0.05522139]]\n",
      "[[0.05518125]]\n",
      "[[0.05514119]]\n",
      "[[0.05510122]]\n",
      "[[0.05506134]]\n",
      "[[0.05502154]]\n",
      "[[0.05498182]]\n",
      "[[0.05494219]]\n",
      "[[0.05490264]]\n",
      "[[0.05486317]]\n",
      "[[0.05482379]]\n",
      "[[0.05478449]]\n",
      "[[0.05474528]]\n",
      "[[0.05470615]]\n",
      "[[0.05466709]]\n",
      "[[0.05462813]]\n",
      "[[0.05458924]]\n",
      "[[0.05455043]]\n",
      "[[0.05451171]]\n",
      "[[0.05447307]]\n",
      "[[0.0544345]]\n",
      "[[0.05439602]]\n",
      "[[0.05435762]]\n",
      "[[0.05431929]]\n",
      "[[0.05428105]]\n",
      "[[0.05424289]]\n",
      "[[0.0542048]]\n",
      "[[0.0541668]]\n",
      "[[0.05412887]]\n",
      "[[0.05409102]]\n",
      "[[0.05405325]]\n",
      "[[0.05401555]]\n",
      "[[0.05397793]]\n",
      "[[0.05394039]]\n",
      "[[0.05390293]]\n",
      "[[0.05386554]]\n",
      "[[0.05382823]]\n",
      "[[0.053791]]\n",
      "[[0.05375384]]\n",
      "[[0.05371676]]\n",
      "[[0.05367975]]\n",
      "[[0.05364282]]\n",
      "[[0.05360596]]\n",
      "[[0.05356918]]\n",
      "[[0.05353247]]\n",
      "[[0.05349584]]\n",
      "[[0.05345928]]\n",
      "[[0.05342279]]\n",
      "[[0.05338638]]\n",
      "[[0.05335004]]\n",
      "[[0.05331377]]\n",
      "[[0.05327758]]\n",
      "[[0.05324145]]\n",
      "[[0.0532054]]\n",
      "[[0.05316943]]\n",
      "[[0.05313352]]\n",
      "[[0.05309768]]\n",
      "[[0.05306192]]\n",
      "[[0.05302623]]\n",
      "[[0.05299061]]\n",
      "[[0.05295505]]\n",
      "[[0.05291957]]\n",
      "[[0.05288416]]\n",
      "[[0.05284882]]\n",
      "[[0.05281355]]\n",
      "[[0.05277835]]\n",
      "[[0.05274321]]\n",
      "[[0.05270815]]\n",
      "[[0.05267315]]\n",
      "[[0.05263823]]\n",
      "[[0.05260337]]\n",
      "[[0.05256858]]\n",
      "[[0.05253386]]\n",
      "[[0.0524992]]\n",
      "[[0.05246461]]\n",
      "[[0.05243009]]\n",
      "[[0.05239564]]\n",
      "[[0.05236125]]\n",
      "[[0.05232693]]\n",
      "[[0.05229268]]\n",
      "[[0.05225849]]\n",
      "[[0.05222437]]\n",
      "[[0.05219032]]\n",
      "[[0.05215633]]\n",
      "[[0.0521224]]\n",
      "[[0.05208854]]\n",
      "[[0.05205475]]\n",
      "[[0.05202102]]\n",
      "[[0.05198735]]\n",
      "[[0.05195375]]\n",
      "[[0.05192021]]\n",
      "[[0.05188674]]\n",
      "[[0.05185333]]\n",
      "[[0.05181999]]\n",
      "[[0.0517867]]\n",
      "[[0.05175348]]\n",
      "[[0.05172033]]\n",
      "[[0.05168723]]\n",
      "[[0.0516542]]\n",
      "[[0.05162123]]\n",
      "[[0.05158833]]\n",
      "[[0.05155548]]\n",
      "[[0.0515227]]\n",
      "[[0.05148998]]\n",
      "[[0.05145732]]\n",
      "[[0.05142472]]\n",
      "[[0.05139218]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1721/2360933435.py:24: RuntimeWarning: divide by zero encountered in log\n",
      "  j = (-1 / m) * (np.dot(y.T, np.log(h)) + np.dot((1 - y).T, np.log(1 - h)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "[[nan]]\n",
      "The cost after training is nan.\n",
      "The resulting vector of weights is [1e-07, 0.0004809, 0.00028989]\n"
     ]
    }
   ],
   "source": [
    "# collect the features x and stack them into a matrix X\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :] = extract_features(train_x[i], build_freqs())\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = train_y\n",
    "\n",
    "# apply gradient descent\n",
    "j, theta = gradient_descent(X, Y, np.zeros((3, 1)), 1e-9, 1500)\n",
    "print(f\"The cost after training is {j:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "incomplete format",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 52\u001b[0m\n\u001b[1;32m     48\u001b[0m     accuracy \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((test_y \u001b[39m==\u001b[39m y_hat)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m))\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(test_x)\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m accuracy\n\u001b[0;32m---> 52\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39;49m\u001b[39maccuracy of model: \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m test_logistic_regression(test_x, test_y, build_freqs(), theta))\n",
      "\u001b[0;31mValueError\u001b[0m: incomplete format"
     ]
    }
   ],
   "source": [
    "def predict_review(review, freqs, theta):\n",
    "    '''\n",
    "    input: \n",
    "        tweet: a string\n",
    "        freqs: a dictionary corresponding to the frequencies of each tuple (word, label)\n",
    "        theta: (3,1) vector of weights\n",
    "    output: \n",
    "        y_pred: the probability of a tweet being positive or negative\n",
    "    '''\n",
    "    \n",
    "    # extract the features of the tweet and store it into x\n",
    "    x = extract_features(review, freqs)\n",
    "    \n",
    "    # make the prediction using x and theta\n",
    "    z = np.dot(x, theta)\n",
    "    y_pred = sigmoid(z)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def test_logistic_regression(test_x, test_y, freqs, theta):\n",
    "    \"\"\"\n",
    "    input: \n",
    "        test_x: a list of reviews\n",
    "        test_y: (m, 1) vector with the corresponding labels for the list of reviews\n",
    "        freqs: a dictionary with the frequency of each pair (or tuple)\n",
    "        theta: weight vector of dimension (3, 1)\n",
    "    output: \n",
    "        accuracy: (# of tweets classified correctly) / (total # of reviews)\n",
    "    \"\"\"\n",
    "        \n",
    "    # the list for storing predictions\n",
    "    y_hat = []\n",
    "    \n",
    "    for review in test_x:\n",
    "        # get the label prediction for the tweet\n",
    "        y_pred = predict_review(review, freqs, theta)\n",
    "        \n",
    "        if y_pred > 0.5:\n",
    "            # append 1.0 to the list\n",
    "            y_hat.append(1)\n",
    "        else:\n",
    "            # append 0 to the list\n",
    "            y_hat.append(0)\n",
    "\t\t# With the above implementation, y_hat is a list, but test_y is (m,1) array\n",
    "    # convert both to one-dimensional arrays in order to compare them using the '==' operator\n",
    "    y_hat = np.array(y_hat)\n",
    "    test_y = test_y.reshape(-1)\n",
    "    accuracy = np.sum((test_y == y_hat).astype(int))/len(test_x)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "print(\"accuracy of model: %\" % test_logistic_regression(test_x, test_y, build_freqs(), theta))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
